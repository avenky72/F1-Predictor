{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyarrow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup\n",
    "cache_path = Path('cache')\n",
    "cache_path.mkdir(exist_ok=True)\n",
    "fastf1.Cache.enable_cache(str(cache_path))\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_save_season(year, output_format=\"csv\"):\n",
    "    output_dir = Path(f\"data/raw/{year}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_races = []\n",
    "    schedule = fastf1.get_event_schedule(year)\n",
    "    num_races = len(schedule)\n",
    "    print(f\"Collecting {year} season ({num_races} races)...\")\n",
    "\n",
    "    for round_num in range(1, num_races + 1):\n",
    "        try:\n",
    "            print(f\"  Round {round_num}...\", end=\"\")\n",
    "            session = fastf1.get_session(year, round_num, \"R\")\n",
    "            session.load(laps=True, telemetry=False, weather=True, messages=True)\n",
    "\n",
    "            # Check what columns are actually available\n",
    "            available_columns = session.results.columns.tolist()\n",
    "            \n",
    "            # Only keep columns that exist\n",
    "            keep_base = [\"Abbreviation\",\"FullName\",\"TeamName\",\"GridPosition\",\"Position\",\"Points\",\"Status\",\"Time\"]\n",
    "            keep = [col for col in keep_base if col in available_columns]\n",
    "            \n",
    "            race = session.results[keep].copy()\n",
    "            race[\"Year\"] = year\n",
    "            race[\"Round\"] = round_num\n",
    "            race[\"TrackName\"] = session.event[\"EventName\"]\n",
    "            race[\"Country\"] = session.event[\"Country\"]\n",
    "\n",
    "            # Get Laps from session.laps if not in results\n",
    "            if 'Laps' not in available_columns and session.laps is not None and not session.laps.empty:\n",
    "                laps_completed = session.laps.groupby('Driver')['LapNumber'].max()\n",
    "                race = race.merge(\n",
    "                    laps_completed.rename('Laps').reset_index().rename(columns={'Driver': 'Abbreviation'}),\n",
    "                    on='Abbreviation',\n",
    "                    how='left'\n",
    "                )\n",
    "            elif 'Laps' in available_columns:\n",
    "                # If Laps is in results, it's already in race dataframe\n",
    "                pass\n",
    "\n",
    "            if session.laps is not None and not session.laps.empty:\n",
    "                lap_agg = (\n",
    "                    session.laps.groupby(\"Driver\")\n",
    "                    .agg(\n",
    "                        AvgLapTime=(\"LapTime\", lambda s: s.dt.total_seconds().mean()),\n",
    "                        NumPitStops=(\"PitInTime\", lambda s: s.notna().sum()),\n",
    "                    )\n",
    "                    .reset_index()\n",
    "                    .rename(columns={\"Driver\": \"Abbreviation\"})\n",
    "                )\n",
    "                race = race.merge(lap_agg, on=\"Abbreviation\", how=\"left\")\n",
    "\n",
    "            if session.weather_data is not None and not session.weather_data.empty:\n",
    "                race[\"AvgTrackTemp\"] = float(session.weather_data[\"TrackTemp\"].mean())\n",
    "                race[\"AvgAirTemp\"] = float(session.weather_data[\"AirTemp\"].mean())\n",
    "                race[\"RainDuringRace\"] = bool(session.weather_data[\"Rainfall\"].any())\n",
    "\n",
    "            sc = False\n",
    "            rcm = getattr(session, \"race_control_messages\", None)\n",
    "            if rcm is not None and not rcm.empty:\n",
    "                sc = bool(rcm[\"Message\"].str.contains(\"SAFETY CAR\", na=False).any())\n",
    "            race[\"SafetyCarDeployed\"] = sc\n",
    "\n",
    "            all_races.append(race)\n",
    "            print(f\" ✓ {session.event['EventName']}\")\n",
    "        except Exception as e:\n",
    "            print(f\" ✗ Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_races:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    combined = pd.concat(all_races, ignore_index=True)\n",
    "    output_file = output_dir / (f\"{year}_season_extended.csv\" if output_format == \"csv\" else f\"{year}_season_extended.parquet\")\n",
    "    if output_format == \"csv\":\n",
    "        combined.to_csv(output_file, index=False)\n",
    "    else:\n",
    "        combined.to_parquet(output_file, index=False)\n",
    "    print(f\"Saved {len(all_races)} races to {output_file}\")\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 2023 and 2022 data\n",
    "for year in [2022, 2023]:\n",
    "    data = collect_and_save_season(year, output_format='csv')\n",
    "    if not data.empty:\n",
    "        print(f\"{year}: Collected {len(data)} driver entries from {data['Round'].nunique()} races\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_season_data(year):\n",
    "    p = Path(f\"data/raw/{year}\")\n",
    "    for fn in [f\"{year}_season_extended.csv\", f\"{year}_season_extended.parquet\",\n",
    "               f\"{year}_season.csv\", f\"{year}_season.parquet\"]:\n",
    "        f = p / fn\n",
    "        if f.exists():\n",
    "            return pd.read_csv(f) if f.suffix==\".csv\" else pd.read_parquet(f)\n",
    "    print(f\"No data files found for {year}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def load_multiple_seasons(years):\n",
    "    all_seasons = []\n",
    "    for year in years:\n",
    "        season_data = load_season_data(year)\n",
    "        if not season_data.empty:\n",
    "            all_seasons.append(season_data)\n",
    "    \n",
    "    if all_seasons:\n",
    "        return pd.concat(all_seasons, ignore_index=True)\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 0)\n",
    "\n",
    "def load_season_data(year: int) -> pd.DataFrame:\n",
    "    base = Path(f\"data/raw/{year}\")\n",
    "    for f in [base / f\"{year}_season_extended.parquet\",\n",
    "              base / f\"{year}_season_extended.csv\",\n",
    "              base / f\"{year}_season.parquet\",\n",
    "              base / f\"{year}_season.csv\"]:\n",
    "        if f.exists():\n",
    "            return pd.read_parquet(f) if f.suffix == \".parquet\" else pd.read_csv(f)\n",
    "    print(f\"[warn] No data files found for {year}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def load_multiple_seasons(years) -> pd.DataFrame:\n",
    "    frames = [load_season_data(y) for y in years]\n",
    "    frames = [f for f in frames if not f.empty]\n",
    "    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "\n",
    "train_data = load_multiple_seasons([2023, 2022])\n",
    "print(f\"\\nCombined training data: {train_data.shape}\")\n",
    "\n",
    "for c in [\"GridPosition\",\"Position\",\"Points\",\"Laps\",\"Year\",\"Round\",\"AvgLapTime\",\"NumPitStops\",\"AvgTrackTemp\",\"AvgAirTemp\"]:\n",
    "    if c in train_data.columns:\n",
    "        train_data[c] = pd.to_numeric(train_data[c], errors=\"coerce\")\n",
    "\n",
    "train_data[\"Time\"] = pd.to_timedelta(train_data.get(\"Time\", pd.Series([np.nan]*len(train_data))), errors=\"coerce\")\n",
    "\n",
    "for bc in [\"RainDuringRace\",\"SafetyCarDeployed\"]:\n",
    "    if bc in train_data.columns:\n",
    "        train_data[bc] = train_data[bc].astype(\"boolean\")\n",
    "\n",
    "is_winner = train_data[\"Position\"] == 1.0\n",
    "train_data[\"GapToWinner_s\"] = np.where(is_winner, 0.0, train_data[\"Time\"].dt.total_seconds())\n",
    "\n",
    "train_data[\"WinnerRaceTime_s\"] = (\n",
    "    train_data.groupby([\"Year\",\"Round\"])[\"Time\"]\n",
    "              .transform(lambda s: s.max().total_seconds() if s.notna().any() else np.nan)\n",
    ")\n",
    "\n",
    "train_data[\"Time_s\"] = train_data[\"WinnerRaceTime_s\"] + train_data[\"GapToWinner_s\"]\n",
    "\n",
    "def _fmt_hms_ms(sec):\n",
    "    if pd.isna(sec): return np.nan\n",
    "    sec = float(sec)\n",
    "    ms = int(round((sec - int(sec)) * 1000))\n",
    "    if ms == 1000:\n",
    "        ms = 0\n",
    "        sec = int(sec) + 1\n",
    "    s = int(sec) % 60\n",
    "    m = (int(sec) // 60) % 60\n",
    "    h = int(sec) // 3600\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}.{ms:03d}\"\n",
    "\n",
    "train_data[\"Time_str\"] = train_data[\"Time_s\"].apply(_fmt_hms_ms)\n",
    "\n",
    "train_data = train_data.rename(columns={\"Position\":\"RacePosition\",\"GridPosition\":\"QualifyingPosition\"})\n",
    "\n",
    "for cat in [\"Abbreviation\",\"FullName\",\"TeamName\",\"Status\",\"TrackName\",\"Country\"]:\n",
    "    if cat in train_data.columns:\n",
    "        train_data[cat] = train_data[cat].astype(\"string\").fillna(pd.NA).str.strip()\n",
    "\n",
    "if \"Status\" in train_data.columns:\n",
    "    train_data[\"FinishedFlag\"] = train_data[\"Status\"].str.lower().eq(\"finished\").astype(\"Int8\")\n",
    "\n",
    "train_data = train_data.drop(columns=[\"Time\"])\n",
    "\n",
    "cols_order = [\n",
    "    \"Year\",\"Round\",\"TrackName\",\"Country\",\n",
    "    \"Abbreviation\",\"FullName\",\"TeamName\",\"Status\",\n",
    "    \"QualifyingPosition\",\"RacePosition\",\"Points\",\"Laps\",\n",
    "    \"AvgLapTime\",\"NumPitStops\",\"AvgTrackTemp\",\"AvgAirTemp\",\n",
    "    \"RainDuringRace\",\"SafetyCarDeployed\",\n",
    "    \"Time_s\",\"Time_str\",\"GapToWinner_s\",\"WinnerRaceTime_s\",\n",
    "    \"FinishedFlag\"\n",
    "]\n",
    "train_data = train_data[[c for c in cols_order if c in train_data.columns]]\n",
    "\n",
    "out_dir = Path(\"data/processed\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "csv_path = out_dir / \"f1_2022_2023_processed.csv\"\n",
    "parq_path = out_dir / \"f1_2022_2023_processed.parquet\"\n",
    "\n",
    "train_data.to_csv(csv_path, index=False)\n",
    "try:\n",
    "    train_data.to_parquet(parq_path, index=False)\n",
    "except Exception as e:\n",
    "    print(f\"[warn] parquet save failed: {e}\")\n",
    "\n",
    "print(f\"\\nSaved processed data to:\\n- {csv_path}\\n- {parq_path if parq_path.exists() else '(parquet not written)'}\")\n",
    "print(\"\\nPreview:\")\n",
    "print(train_data.head(8).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes\n",
    "(\n",
    "    train_data[train_data['RainDuringRace'] == False]  \n",
    "    .groupby('TrackName')['AvgLapTime']    \n",
    "    .mean()\n",
    "    .sort_values()\n",
    "    .apply(_fmt_hms_ms)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_avg_speeds = {}\n",
    "unique_tracks = train_data['TrackName'].unique()\n",
    "\n",
    "for track in unique_tracks:\n",
    "    mask = (train_data['TrackName'] == track) & (train_data['RainDuringRace'] == False)\n",
    "    track_avg_speeds[track] = train_data[mask]['AvgLapTime'].mean()\n",
    "\n",
    "print(track_avg_speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_2023 = [\n",
    "    'Bahrain Grand Prix',\n",
    "    'Saudi Arabian Grand Prix', \n",
    "    'Australian Grand Prix',\n",
    "    'Azerbaijan Grand Prix',\n",
    "    'Miami Grand Prix',\n",
    "    'Monaco Grand Prix',\n",
    "    'Spanish Grand Prix',\n",
    "    'Canadian Grand Prix',\n",
    "    'Austrian Grand Prix',\n",
    "    'British Grand Prix',\n",
    "    'Hungarian Grand Prix',\n",
    "    'Belgian Grand Prix',\n",
    "    'Dutch Grand Prix',\n",
    "    'Italian Grand Prix',\n",
    "    'Singapore Grand Prix',  \n",
    "    'Japanese Grand Prix',  \n",
    "    'Qatar Grand Prix',\n",
    "    'United States Grand Prix',\n",
    "    'Mexico City Grand Prix',\n",
    "    'São Paulo Grand Prix',\n",
    "    'Las Vegas Grand Prix', \n",
    "    'Abu Dhabi Grand Prix'\n",
    "]\n",
    "\n",
    "train_data_2023 = train_data[train_data['TrackName'].isin(tracks_2023)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "sprint_races = [(2022, 'Emilia Romagna Grand Prix'),(2022, 'Austrian Grand Prix'), (2022, 'São Paulo Grand Prix'),(2023, 'Azerbaijan Grand Prix'),(2023, 'Austrian Grand Prix'),(2023, 'Belgian Grand Prix'),(2023, 'Qatar Grand Prix'),(2023, 'United States Grand Prix'),(2023, 'São Paulo Grand Prix')]\n",
    "\n",
    "is_sprint = pd.Series([False] * len(train_data), index=train_data.index)\n",
    "for year, track in sprint_races:\n",
    "    is_sprint |= ((train_data['Year'] == year) & (train_data['TrackName'] == track))\n",
    "\n",
    "\n",
    "train_data_no_sprints = train_data[~is_sprint]\n",
    "\n",
    "\n",
    "\n",
    "overtake_difficulty_clean = {}\n",
    "street_circuits = ['Monaco Grand Prix', 'Azerbaijan Grand Prix', 'Saudi Arabian Grand Prix', 'Miami Grand Prix']\n",
    "\n",
    "\n",
    "unique_tracks = train_data_no_sprints['TrackName'].unique()\n",
    "\n",
    "\n",
    "for track in unique_tracks:\n",
    "    mask = ((train_data_no_sprints['TrackName'] == track) & \n",
    "            (train_data_no_sprints['FinishedFlag'] == 1))\n",
    "    \n",
    "    data = train_data_no_sprints[mask][['QualifyingPosition', 'RacePosition']]\n",
    "    data = data.dropna()\n",
    "    \n",
    "    \n",
    "    if len(data) > 5:\n",
    "        correlation = data['QualifyingPosition'].corr(data['RacePosition'])\n",
    "        overtake_difficulty_clean[track] = correlation\n",
    "    \n",
    "    else:\n",
    "        if track in street_circuits:\n",
    "            overtake_difficulty_clean[track] = 0.8\n",
    "        else:\n",
    "            overtake_difficulty_clean[track] = 0.6\n",
    "\n",
    "\n",
    "print(overtake_difficulty_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create track features with just 2 features\n",
    "track_features = pd.DataFrame({'TrackName': list(overtake_difficulty_clean.keys()), 'overtaking_difficulty': list(overtake_difficulty_clean.values())})\n",
    "\n",
    "street_circuits = ['Monaco Grand Prix', 'Azerbaijan Grand Prix', 'Saudi Arabian Grand Prix', 'Miami Grand Prix']\n",
    "track_features['is_street'] = track_features['TrackName'].isin(street_circuits).astype(int)\n",
    "\n",
    "print(track_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_features = train_data_no_sprints.merge(\n",
    "    track_features, \n",
    "    on='TrackName', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(train_data_with_features[['TrackName', 'is_street', 'overtaking_difficulty']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_with_features[train_data_with_features['is_street'] == 1]['TrackName'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quali_points = {1:8, 2:7, 3:6, 4:5, 5:4, 6:3, 7:2, 8:1, 9:0, 10:0, 11:0, 12:0, 13:0, 14:0, 15:0, 16:0, 17:0, 18:0, 19:0, 20:0}\n",
    "recent_form = {}\n",
    "\n",
    "for year in [2022, 2023]:\n",
    "    season_data = train_data[train_data['Year'] == year]\n",
    "    \n",
    "    max_round = season_data['Round'].max()\n",
    "    for race in range(4, max_round + 1):\n",
    "        current_round = season_data[season_data['Round'] == race]\n",
    "            \n",
    "        for driver in current_round[\"Abbreviation\"].unique():\n",
    "            prev_race1 = season_data[(season_data['Round'] == race-1) & (season_data['Abbreviation'] == driver)]\n",
    "            points1 = prev_race1['Points'].sum()\n",
    "            prev_race2 = season_data[(season_data['Round'] == race-2) & (season_data['Abbreviation'] == driver)]\n",
    "            points2 = prev_race2['Points'].sum()\n",
    "            prev_race3 = season_data[(season_data['Round'] == race-3) & (season_data['Abbreviation'] == driver)]\n",
    "            points3 = prev_race3['Points'].sum()\n",
    "            \n",
    "            points = sum([points1, points2, points3])\n",
    "            \n",
    "            quali1 = prev_race1['QualifyingPosition'].sum()\n",
    "            sprint_points1 = quali_points.get(quali1, 0)\n",
    "            quali2 = prev_race2['QualifyingPosition'].sum()\n",
    "            sprint_points2 = quali_points.get(quali2, 0)\n",
    "            quali3 = prev_race3['QualifyingPosition'].sum()\n",
    "            sprint_points3 = quali_points.get(quali3, 0)\n",
    "            \n",
    "            points += sum([sprint_points1, sprint_points2, sprint_points3])\n",
    "            \n",
    "            recent_form[(year, race, driver)] = points\n",
    "\n",
    "train_data['recent_form'] = np.nan\n",
    "\n",
    "for key, form_value in recent_form.items():\n",
    "    year, round_num, driver_code = key  \n",
    "    \n",
    "    season = train_data['Year'] == year\n",
    "    race = train_data['Round'] == round_num  \n",
    "    racer = train_data['Abbreviation'] == driver_code\n",
    "    \n",
    "    row_to_update = season & race & racer\n",
    "    \n",
    "    train_data.loc[row_to_update, 'recent_form'] = form_value\n",
    "    \n",
    "print(recent_form[(2022, 4, 'HAM')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_specialists = ['VER', 'HAM', 'STR']\n",
    "train_data['rain_specialist'] = train_data['Abbreviation'].isin(rain_specialists).astype(int)\n",
    "print(train_data[train_data['RainDuringRace'] == True][['Abbreviation', 'rain_specialist', 'RacePosition']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DNF positions\n",
    "dnf = train_data[~train_data['Status'].isin(['Finished', '+1 Lap', '+2 Laps', '+3 Laps'])]\n",
    "print(dnf[['Status', 'RacePosition', 'QualifyingPosition', 'Laps']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_error = ['Collision', 'Collision damage', 'Accident', 'Spun off']\n",
    "mechanical = ['Engine', 'Gearbox', 'Power Unit', 'Hydraulics', 'Brakes', 'Suspension', 'Fuel pressure', 'Power loss', 'Water pressure', 'Water leak', 'Mechanical', 'Undertray', 'Turbo', 'Oil leak', 'Cooling system', 'Vibrations', 'Differential', ...]\n",
    "lapped = ['+1 Lap', '+2 Laps', '+3 Laps']\n",
    "\n",
    "\n",
    "\n",
    "adjusted_positions = []\n",
    "\n",
    "for index, row in train_data.iterrows():\n",
    "\n",
    "    if row['Status'] == \"Finished\" or row['Status'] in lapped:\n",
    "        adjusted_positions.append(row['RacePosition'])\n",
    "        \n",
    "    elif row['Status'] in mechanical:\n",
    "        adjusted_positiondnf = (row['RacePosition'] + row['QualifyingPosition']) / 2\n",
    "        adjusted_positions.append(adjusted_positiondnf)\n",
    "    \n",
    "    elif row['Status'] in driver_error:\n",
    "        adjusted_positions.append(row['RacePosition'])\n",
    "    \n",
    "    else:\n",
    "        adjusted_positions.append(row['RacePosition'])\n",
    "\n",
    "train_data['adjusted_position'] = adjusted_positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.shape\n",
    "#train_data.info()\n",
    "#train_data.describe()\n",
    "train_data.head()\n",
    "#train_data[train_data['Points'] > 6].head()\n",
    "#train_data.groupby('Abbreviation')['Points'].sum().head()\n",
    "train_data[train_data['Year'] == 2023].groupby('Abbreviation')['Points'].sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
