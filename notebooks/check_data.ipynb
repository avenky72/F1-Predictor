{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyarrow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup\n",
    "cache_path = Path('cache')\n",
    "cache_path.mkdir(exist_ok=True)\n",
    "fastf1.Cache.enable_cache(str(cache_path))\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_save_season_individual(year, rounds_to_collect=None):\n",
    "    \"\"\"\n",
    "    Collect F1 season data and save each race as individual file.\n",
    "    \n",
    "    Args:\n",
    "        year: Season year\n",
    "        rounds_to_collect: List of specific rounds to collect (None = all)\n",
    "    \"\"\"\n",
    "    output_dir = Path(f\"data/raw/{year}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    schedule = fastf1.get_event_schedule(year)\n",
    "    num_races = len(schedule)\n",
    "    \n",
    "    if rounds_to_collect is None:\n",
    "        rounds_to_collect = range(1, num_races + 1)\n",
    "    \n",
    "    print(f\"Collecting {year} season - {len(rounds_to_collect)} races\")\n",
    "    \n",
    "    for round_num in rounds_to_collect:\n",
    "        # Check if file already exists\n",
    "        race_file = output_dir / f\"{year}_round_{round_num:02d}.csv\"\n",
    "        if race_file.exists():\n",
    "            print(f\"  Round {round_num}: Already exists, skipping\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            print(f\"  Round {round_num}...\", end=\"\")\n",
    "            session = fastf1.get_session(year, round_num, \"R\")\n",
    "            session.load(laps=True, telemetry=False, weather=True, messages=True)\n",
    "            \n",
    "            # Check available columns\n",
    "            available_columns = session.results.columns.tolist()\n",
    "            keep_base = [\"Abbreviation\",\"FullName\",\"TeamName\",\"GridPosition\",\"Position\",\"Points\",\"Status\",\"Time\"]\n",
    "            keep = [col for col in keep_base if col in available_columns]\n",
    "            \n",
    "            race = session.results[keep].copy()\n",
    "            race[\"Year\"] = year\n",
    "            race[\"Round\"] = round_num\n",
    "            race[\"TrackName\"] = session.event[\"EventName\"]\n",
    "            race[\"Country\"] = session.event[\"Country\"]\n",
    "            \n",
    "            # Get Laps from session.laps if needed\n",
    "            if 'Laps' not in available_columns and session.laps is not None and not session.laps.empty:\n",
    "                laps_completed = session.laps.groupby('Driver')['LapNumber'].max()\n",
    "                race = race.merge(\n",
    "                    laps_completed.rename('Laps').reset_index().rename(columns={'Driver': 'Abbreviation'}),\n",
    "                    on='Abbreviation',\n",
    "                    how='left'\n",
    "                )\n",
    "            \n",
    "            # Add lap statistics\n",
    "            if session.laps is not None and not session.laps.empty:\n",
    "                lap_agg = (\n",
    "                    session.laps.groupby(\"Driver\")\n",
    "                    .agg(\n",
    "                        AvgLapTime=(\"LapTime\", lambda s: s.dt.total_seconds().mean()),\n",
    "                        NumPitStops=(\"PitInTime\", lambda s: s.notna().sum()),\n",
    "                    )\n",
    "                    .reset_index()\n",
    "                    .rename(columns={\"Driver\": \"Abbreviation\"})\n",
    "                )\n",
    "                race = race.merge(lap_agg, on=\"Abbreviation\", how=\"left\")\n",
    "            \n",
    "            # Add weather data\n",
    "            if session.weather_data is not None and not session.weather_data.empty:\n",
    "                race[\"AvgTrackTemp\"] = float(session.weather_data[\"TrackTemp\"].mean())\n",
    "                race[\"AvgAirTemp\"] = float(session.weather_data[\"AirTemp\"].mean())\n",
    "                race[\"RainDuringRace\"] = bool(session.weather_data[\"Rainfall\"].any())\n",
    "            \n",
    "            # Check for safety car\n",
    "            sc = False\n",
    "            rcm = getattr(session, \"race_control_messages\", None)\n",
    "            if rcm is not None and not rcm.empty:\n",
    "                sc = bool(rcm[\"Message\"].str.contains(\"SAFETY CAR\", na=False).any())\n",
    "            race[\"SafetyCarDeployed\"] = sc\n",
    "            \n",
    "            # Save individual race\n",
    "            race.to_csv(race_file, index=False)\n",
    "            print(f\" ✓ {session.event['EventName']} saved\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" ✗ Error: {e}\")\n",
    "            continue\n",
    "\n",
    "def combine_season_files(year):\n",
    "    \"\"\"Combine individual race files into one season file.\"\"\"\n",
    "    data_dir = Path(f\"data/raw/{year}\")\n",
    "    race_files = sorted(data_dir.glob(f\"{year}_round_*.csv\"))\n",
    "    \n",
    "    if not race_files:\n",
    "        print(f\"No race files found for {year}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    all_races = []\n",
    "    for file in race_files:\n",
    "        df = pd.read_csv(file)\n",
    "        all_races.append(df)\n",
    "    \n",
    "    combined = pd.concat(all_races, ignore_index=True)\n",
    "    output_file = data_dir / f\"{year}_season_combined.csv\"\n",
    "    combined.to_csv(output_file, index=False)\n",
    "    print(f\"Combined {len(race_files)} races into {output_file}\")\n",
    "    return combined\n",
    "\n",
    "# Usage examples:\n",
    "\n",
    "# Collect all races for a year (skips existing files)\n",
    "collect_and_save_season_individual(2023)\n",
    "\n",
    "# Collect only specific races (e.g., just Hungarian GP which is round 11)\n",
    "collect_and_save_season_individual(2023, rounds_to_collect=[11])\n",
    "\n",
    "# Combine all individual files into one\n",
    "train_data_2023 = pd.read_csv('data/raw/2023/2023_season_complete.csv')\n",
    "train_data_2022 = pd.read_csv('data/raw/2022/2022_season_extended.csv')\n",
    "train_data = pd.concat([train_data_2023, train_data_2022], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data with individual race files\n",
    "for year in [2022, 2023]:\n",
    "    # Check if we need to collect\n",
    "    data_dir = Path(f\"data/raw/{year}\")\n",
    "    if data_dir.exists() and len(list(data_dir.glob(f\"{year}_round_*.csv\"))) > 0:\n",
    "        print(f\"{year}: Found existing race files, combining...\")\n",
    "        data = combine_season_files(year)\n",
    "    else:\n",
    "        print(f\"{year}: Collecting races individually...\")\n",
    "        collect_and_save_season_individual(year)\n",
    "        data = combine_season_files(year)\n",
    "    \n",
    "    if not data.empty:\n",
    "        print(f\"{year}: {len(data)} driver entries from {data['Round'].nunique()} races\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def load_season_data(year):\n",
    "    p = Path(f\"data/raw/{year}\")\n",
    "    # Check for combined files first\n",
    "    for fn in [f\"{year}_season_combined.csv\", f\"{year}_season_extended.csv\", \n",
    "               f\"{year}_season.csv\", f\"{year}_season.parquet\"]:\n",
    "        f = p / fn\n",
    "        if f.exists():\n",
    "            return pd.read_csv(f) if f.suffix == \".csv\" else pd.read_parquet(f)\n",
    "    \n",
    "    # If no combined file, try to combine individual race files\n",
    "    race_files = sorted(p.glob(f\"{year}_round_*.csv\"))\n",
    "    if race_files:\n",
    "        print(f\"Found {len(race_files)} individual race files for {year}, combining...\")\n",
    "        all_races = []\n",
    "        for file in race_files:\n",
    "            df = pd.read_csv(file)\n",
    "            all_races.append(df)\n",
    "        return pd.concat(all_races, ignore_index=True)\n",
    "    \n",
    "    print(f\"No data files found for {year}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def load_multiple_seasons(years):\n",
    "    all_seasons = []\n",
    "    for year in years:\n",
    "        season_data = load_season_data(year)\n",
    "        if not season_data.empty:\n",
    "            all_seasons.append(season_data)\n",
    "    \n",
    "    if all_seasons:\n",
    "        return pd.concat(all_seasons, ignore_index=True)\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 0)\n",
    "\n",
    "# Load data using the functions from previous cell\n",
    "train_data = load_multiple_seasons([2023, 2022])\n",
    "print(f\"\\nCombined training data: {train_data.shape}\")\n",
    "\n",
    "# Convert numeric columns\n",
    "for c in [\"GridPosition\",\"Position\",\"Points\",\"Laps\",\"Year\",\"Round\",\"AvgLapTime\",\"NumPitStops\",\"AvgTrackTemp\",\"AvgAirTemp\"]:\n",
    "    if c in train_data.columns:\n",
    "        train_data[c] = pd.to_numeric(train_data[c], errors=\"coerce\")\n",
    "\n",
    "# Handle time data\n",
    "train_data[\"Time\"] = pd.to_timedelta(train_data.get(\"Time\", pd.Series([np.nan]*len(train_data))), errors=\"coerce\")\n",
    "\n",
    "# Convert boolean columns\n",
    "for bc in [\"RainDuringRace\",\"SafetyCarDeployed\"]:\n",
    "    if bc in train_data.columns:\n",
    "        train_data[bc] = train_data[bc].astype(\"boolean\")\n",
    "\n",
    "# Calculate time gaps\n",
    "is_winner = train_data[\"Position\"] == 1.0\n",
    "train_data[\"GapToWinner_s\"] = np.where(is_winner, 0.0, train_data[\"Time\"].dt.total_seconds())\n",
    "\n",
    "train_data[\"WinnerRaceTime_s\"] = (\n",
    "    train_data.groupby([\"Year\",\"Round\"])[\"Time\"]\n",
    "              .transform(lambda s: s.max().total_seconds() if s.notna().any() else np.nan)\n",
    ")\n",
    "\n",
    "train_data[\"Time_s\"] = train_data[\"WinnerRaceTime_s\"] + train_data[\"GapToWinner_s\"]\n",
    "\n",
    "def _fmt_hms_ms(sec):\n",
    "    if pd.isna(sec): return np.nan\n",
    "    sec = float(sec)\n",
    "    ms = int(round((sec - int(sec)) * 1000))\n",
    "    if ms == 1000:\n",
    "        ms = 0\n",
    "        sec = int(sec) + 1\n",
    "    s = int(sec) % 60\n",
    "    m = (int(sec) // 60) % 60\n",
    "    h = int(sec) // 3600\n",
    "    return f\"{h:02d}:{m:02d}:{s:02d}.{ms:03d}\"\n",
    "\n",
    "train_data[\"Time_str\"] = train_data[\"Time_s\"].apply(_fmt_hms_ms)\n",
    "\n",
    "# Rename columns\n",
    "train_data = train_data.rename(columns={\"Position\":\"RacePosition\",\"GridPosition\":\"QualifyingPosition\"})\n",
    "\n",
    "# Clean string columns\n",
    "for cat in [\"Abbreviation\",\"FullName\",\"TeamName\",\"Status\",\"TrackName\",\"Country\"]:\n",
    "    if cat in train_data.columns:\n",
    "        train_data[cat] = train_data[cat].astype(\"string\").fillna(pd.NA).str.strip()\n",
    "\n",
    "# Add finished flag\n",
    "if \"Status\" in train_data.columns:\n",
    "    train_data[\"FinishedFlag\"] = train_data[\"Status\"].str.lower().eq(\"finished\").astype(\"Int8\")\n",
    "\n",
    "# Drop original Time column\n",
    "if \"Time\" in train_data.columns:\n",
    "    train_data = train_data.drop(columns=[\"Time\"])\n",
    "\n",
    "# Reorder columns\n",
    "cols_order = [\n",
    "    \"Year\",\"Round\",\"TrackName\",\"Country\",\n",
    "    \"Abbreviation\",\"FullName\",\"TeamName\",\"Status\",\n",
    "    \"QualifyingPosition\",\"RacePosition\",\"Points\",\"Laps\",\n",
    "    \"AvgLapTime\",\"NumPitStops\",\"AvgTrackTemp\",\"AvgAirTemp\",\n",
    "    \"RainDuringRace\",\"SafetyCarDeployed\",\n",
    "    \"Time_s\",\"Time_str\",\"GapToWinner_s\",\"WinnerRaceTime_s\",\n",
    "    \"FinishedFlag\"\n",
    "]\n",
    "train_data = train_data[[c for c in cols_order if c in train_data.columns]]\n",
    "\n",
    "# Save processed data\n",
    "out_dir = Path(\"data/processed\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "csv_path = out_dir / \"f1_2022_2023_processed.csv\"\n",
    "parq_path = out_dir / \"f1_2022_2023_processed.parquet\"\n",
    "\n",
    "train_data.to_csv(csv_path, index=False)\n",
    "try:\n",
    "    train_data.to_parquet(parq_path, index=False)\n",
    "except Exception as e:\n",
    "    print(f\"[warn] parquet save failed: {e}\")\n",
    "\n",
    "print(f\"\\nSaved processed data to:\\n- {csv_path}\\n- {parq_path if parq_path.exists() else '(parquet not written)'}\")\n",
    "print(\"\\nPreview:\")\n",
    "print(train_data.head(8).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes\n",
    "(\n",
    "    train_data[train_data['RainDuringRace'] == False]  \n",
    "    .groupby('TrackName')['AvgLapTime']    \n",
    "    .mean()\n",
    "    .sort_values()\n",
    "    .apply(_fmt_hms_ms)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_avg_speeds = {}\n",
    "unique_tracks = train_data['TrackName'].unique()\n",
    "\n",
    "for track in unique_tracks:\n",
    "    mask = (train_data['TrackName'] == track) & (train_data['RainDuringRace'] == False)\n",
    "    track_avg_speeds[track] = train_data[mask]['AvgLapTime'].mean()\n",
    "\n",
    "print(track_avg_speeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sprint_races = [(2022, 'Emilia Romagna Grand Prix'),(2022, 'Austrian Grand Prix'), (2022, 'São Paulo Grand Prix'),(2023, 'Azerbaijan Grand Prix'),(2023, 'Austrian Grand Prix'),(2023, 'Belgian Grand Prix'),(2023, 'Qatar Grand Prix'),(2023, 'United States Grand Prix'),(2023, 'São Paulo Grand Prix')]\n",
    "\n",
    "is_sprint = pd.Series([False] * len(train_data), index=train_data.index)\n",
    "for year, track in sprint_races:\n",
    "    is_sprint |= ((train_data['Year'] == year) & (train_data['TrackName'] == track))\n",
    "\n",
    "train_data_no_sprints = train_data[~is_sprint]\n",
    "\n",
    "overtake_difficulty_clean = {}\n",
    "street_circuits = ['Monaco Grand Prix', 'Azerbaijan Grand Prix', 'Saudi Arabian Grand Prix', 'Miami Grand Prix']\n",
    "\n",
    "unique_tracks = train_data_no_sprints['TrackName'].unique()\n",
    "\n",
    "for track in unique_tracks:\n",
    "    mask = ((train_data_no_sprints['TrackName'] == track) & \n",
    "            (train_data_no_sprints['FinishedFlag'] == 1))\n",
    "    \n",
    "    data = train_data_no_sprints[mask][['QualifyingPosition', 'RacePosition']].dropna()\n",
    "    \n",
    "    if len(data) > 5:\n",
    "        correlation = data['QualifyingPosition'].corr(data['RacePosition'])\n",
    "        overtake_difficulty_clean[track] = correlation\n",
    "    else:\n",
    "        if track in street_circuits:\n",
    "            overtake_difficulty_clean[track] = 0.8\n",
    "        else:\n",
    "            overtake_difficulty_clean[track] = 0.6\n",
    "\n",
    "print(overtake_difficulty_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create track features with just 2 features\n",
    "track_features = pd.DataFrame({'TrackName': list(overtake_difficulty_clean.keys()), 'overtaking_difficulty': list(overtake_difficulty_clean.values())})\n",
    "\n",
    "street_circuits = ['Monaco Grand Prix', 'Azerbaijan Grand Prix', 'Saudi Arabian Grand Prix', 'Miami Grand Prix']\n",
    "track_features['is_street'] = track_features['TrackName'].isin(street_circuits).astype(int)\n",
    "\n",
    "print(track_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge track features with main data\n",
    "train_data_with_features = train_data_no_sprints.merge(\n",
    "    track_features, \n",
    "    on='TrackName', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Select features for modeling\n",
    "feature_cols = ['QualifyingPosition', 'overtaking_difficulty', 'is_street', \n",
    "                 'AvgLapTime', 'AvgTrackTemp', 'AvgAirTemp', \n",
    "                 'RainDuringRace', 'SafetyCarDeployed']\n",
    "\n",
    "target_col = 'RacePosition'\n",
    "\n",
    "# Remove rows with missing target\n",
    "model_data = train_data_with_features.dropna(subset=[target_col])\n",
    "\n",
    "print(f\"Dataset ready: {len(model_data)} samples\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"Target: {target_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Hungarian GP data\n",
    "hungarian_data = train_data_no_sprints[train_data_no_sprints['TrackName'] == 'Hungarian Grand Prix']\n",
    "print(f\"Hungarian GP races: {hungarian_data['Year'].unique()}\")\n",
    "print(f\"Sample positions:\\n{hungarian_data[['Year', 'QualifyingPosition', 'RacePosition', 'FinishedFlag']].head(30)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_features = train_data_no_sprints.merge(\n",
    "    track_features, \n",
    "    on='TrackName', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(train_data_with_features[['TrackName', 'is_street', 'overtaking_difficulty']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_with_features[train_data_with_features['is_street'] == 1]['TrackName'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quali_points = {1:8, 2:7, 3:6, 4:5, 5:4, 6:3, 7:2, 8:1, 9:0, 10:0, 11:0, 12:0, 13:0, 14:0, 15:0, 16:0, 17:0, 18:0, 19:0, 20:0}\n",
    "recent_form = {}\n",
    "\n",
    "for year in [2022, 2023]:\n",
    "    season_data = train_data[train_data['Year'] == year]\n",
    "    \n",
    "    max_round = season_data['Round'].max()\n",
    "    for race in range(4, max_round + 1):\n",
    "        current_round = season_data[season_data['Round'] == race]\n",
    "            \n",
    "        for driver in current_round[\"Abbreviation\"].unique():\n",
    "            prev_race1 = season_data[(season_data['Round'] == race-1) & (season_data['Abbreviation'] == driver)]\n",
    "            points1 = prev_race1['Points'].sum()\n",
    "            prev_race2 = season_data[(season_data['Round'] == race-2) & (season_data['Abbreviation'] == driver)]\n",
    "            points2 = prev_race2['Points'].sum()\n",
    "            prev_race3 = season_data[(season_data['Round'] == race-3) & (season_data['Abbreviation'] == driver)]\n",
    "            points3 = prev_race3['Points'].sum()\n",
    "            \n",
    "            points = sum([points1, points2, points3])\n",
    "            \n",
    "            quali1 = prev_race1['QualifyingPosition'].sum()\n",
    "            sprint_points1 = quali_points.get(quali1, 0)\n",
    "            quali2 = prev_race2['QualifyingPosition'].sum()\n",
    "            sprint_points2 = quali_points.get(quali2, 0)\n",
    "            quali3 = prev_race3['QualifyingPosition'].sum()\n",
    "            sprint_points3 = quali_points.get(quali3, 0)\n",
    "            \n",
    "            points += sum([sprint_points1, sprint_points2, sprint_points3])\n",
    "            \n",
    "            recent_form[(year, race, driver)] = points\n",
    "\n",
    "train_data['recent_form'] = np.nan\n",
    "\n",
    "for key, form_value in recent_form.items():\n",
    "    year, round_num, driver_code = key  \n",
    "    \n",
    "    season = train_data['Year'] == year\n",
    "    race = train_data['Round'] == round_num  \n",
    "    racer = train_data['Abbreviation'] == driver_code\n",
    "    \n",
    "    row_to_update = season & race & racer\n",
    "    \n",
    "    train_data.loc[row_to_update, 'recent_form'] = form_value\n",
    "    \n",
    "print(recent_form[(2022, 4, 'HAM')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_specialists = ['VER', 'HAM', 'STR']\n",
    "train_data['rain_specialist'] = train_data['Abbreviation'].isin(rain_specialists).astype(int)\n",
    "print(train_data[train_data['RainDuringRace'] == True][['Abbreviation', 'rain_specialist', 'RacePosition']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check DNF positions\n",
    "dnf = train_data[~train_data['Status'].isin(['Finished', '+1 Lap', '+2 Laps', '+3 Laps'])]\n",
    "print(dnf[['Status', 'RacePosition', 'QualifyingPosition', 'Laps']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_error = ['Collision', 'Collision damage', 'Accident', 'Spun off']\n",
    "mechanical = ['Engine', 'Gearbox', 'Power Unit', 'Hydraulics', 'Brakes', 'Suspension', 'Fuel pressure', 'Power loss', 'Water pressure', 'Water leak', 'Mechanical', 'Undertray', 'Turbo', 'Oil leak', 'Cooling system', 'Vibrations', 'Differential', ...]\n",
    "lapped = ['+1 Lap', '+2 Laps', '+3 Laps']\n",
    "\n",
    "\n",
    "\n",
    "adjusted_positions = []\n",
    "\n",
    "for index, row in train_data.iterrows():\n",
    "\n",
    "    if row['Status'] == \"Finished\" or row['Status'] in lapped:\n",
    "        adjusted_positions.append(row['RacePosition'])\n",
    "        \n",
    "    elif row['Status'] in mechanical:\n",
    "        adjusted_positiondnf = (row['RacePosition'] + row['QualifyingPosition']) / 2\n",
    "        adjusted_positions.append(adjusted_positiondnf)\n",
    "    \n",
    "    elif row['Status'] in driver_error:\n",
    "        adjusted_positions.append(row['RacePosition'])\n",
    "    \n",
    "    else:\n",
    "        adjusted_positions.append(row['RacePosition'])\n",
    "\n",
    "train_data['adjusted_position'] = adjusted_positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.shape\n",
    "#train_data.info()\n",
    "#train_data.describe()\n",
    "train_data.head()\n",
    "#train_data[train_data['Points'] > 6].head()\n",
    "#train_data.groupby('Abbreviation')['Points'].sum().head()\n",
    "train_data[train_data['Year'] == 2023].groupby('Abbreviation')['Points'].sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
